- section_name: International Conference / Journal (Peer-reviewed)
  aliases:
    - &adachi "**Kazuki Adachi**"
    - &adachi_jp "**足立 一樹**"
    - &yamaguchi Shin'ya Yamaguchi
    - &kumagai Atsutoshi Kumagai
    - &hamagami Tomoki Hamagami
    - &hamagami_jp 濱上 知樹

  papers:
    - authors:
        - *kumagai
        - Tomoharu Iwata
        - Hiroshi Takahashi
        - Taishi Nishiyama
        - *adachi
        - Yasuhiro Fujiwara
      title: Positive-unlabeled AUC Maximization under Covariate Shift
      published_in: Accepted to 2025 International Conference on Machine Learning (ICML).
      links:
        - Paper: https://openreview.net/forum?id=HQEPgICjBS
      abstract: >-
        Maximizing the area under the receiver operating characteristic curve (AUC) is a standard approach to imbalanced binary classification tasks. Existing AUC maximization methods typically assume that training and test distributions are identical. However, this assumption is often violated due to a covariate shift, where the input distribution can vary but the conditional distribution of the class label given the input remains unchanged. The importance weighting is a common approach to the covariate shift, which minimizes the test risk with importance-weighted training data. However, it cannot maximize the AUC. In this paper, to achieve this, we theoretically derive two estimators of the test AUC risk under the covariate shift by using positive and unlabeled (PU) data in the training distribution and unlabeled data in the test distribution. Our first estimator is calculated from importance-weighted PU data in the training distribution, and the second one is calculated from importance-weighted positive data in the training distribution and unlabeled data in the test distribution. We train classifiers by minimizing a weighted sum of the two AUC risk estimators that approximates the test AUC risk. Unlike the existing importance weighting, our method does not require negative labels and class-priors. We show the effectiveness of our method with six real-world datasets.

    - authors:
        - Sekitoshi Kanai
        - Yasutoshi Ida
        - *adachi
        - Mihiro Uchida
        - Tsukasa Yoshida
        - *yamaguchi
      title: Evaluating Time-Series Training Dataset through Lens of Spectrum in Deep State Space Models
      published_in: Accepted to 2025 International Joint Conference on Neural Networks (IJCNN).
      links:
        - Preprint: https://arxiv.org/abs/2408.16261
      abstract: >-
        This study investigates a method to evaluate time-series datasets in terms of the performance of deep neural networks (DNNs) with state space models (deep SSMs) trained on the dataset.
        SSMs have attracted attention as components inside DNNs to address time-series data.
        Since deep SSMs have powerful representation capacities, training datasets play a crucial role in solving a new task.
        However, the effectiveness of training datasets cannot be known until deep SSMs are actually trained on them.
        This can increase the cost of data collection for new tasks, as a trial-and-error process of data collection and time-consuming training are needed to achieve the necessary performance.
        To advance the practical use of deep SSMs, the metric of datasets to estimate the performance early in the training can be one key element.
        To this end, we introduce the concept of data evaluation methods used in system identification. In system identification of linear dynamical systems, the effectiveness of datasets is evaluated by using the spectrum of input signals.
        We introduce this concept to deep SSMs, which are nonlinear dynamical systems.
        We propose the K-spectral metric, which is the sum of the top-K spectra of signals inside deep SSMs, by focusing on the fact that each layer of a deep SSM can be regarded as a linear dynamical system.
        Our experiments show that the K-spectral metric has a large absolute value of the correlation coefficient with the performance and can be used to evaluate the quality of training datasets.

    - authors:
        - *yamaguchi
        - Dewei Feng
        - Sekitoshi Kanai
        - *adachi
        - Daiki Chijiwa
      title: Post-pre-training for Modality Alignment in Vision-Language Foundation Models
      published_in: "2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Nashville, TN, USA, 2025, pp. 4256-4266, doi: 10.1109/CVPR52734.2025.00402."
      links:
        - Paper: https://openaccess.thecvf.com/content/CVPR2025/html/Yamaguchi_Post-pre-training_for_Modality_Alignment_in_Vision-Language_Foundation_Models_CVPR_2025_paper.html
        - Preprint: https://arxiv.org/abs/2504.12717
        - Topics (NTT): https://group.ntt/en/topics/2025/06/09/cvprntt.html
      abstract: >-
        Contrastive language image pre-training (CLIP) is an essential component of building modern vision-language foundation models. While CLIP demonstrates remarkable zero-shot performance on downstream tasks, the multi-modal feature spaces still suffer from a modality gap, which is a gap between image and text feature clusters and limits downstream task performance. Although existing works attempt to address the modality gap by modifying pre-training or fine-tuning, they struggle with heavy training costs with large datasets or degradations of zero-shot performance. This paper presents CLIP-Refine, a post-pre-training method for CLIP models at a phase between pre-training and fine-tuning. CLIP-Refine aims to align the feature space with 1 epoch training on small image-text datasets without zero-shot performance degradations. To this end, we introduce two techniques: random feature alignment (RaFA) and hybrid contrastive-distillation (HyCD). RaFA aligns the image and text features to follow a shared prior distribution by minimizing the distance to random reference vectors sampled from the prior. HyCD updates the model with hybrid soft labels generated by combining ground-truth image-text pair labels and outputs from the pre-trained CLIP model. This contributes to achieving both maintaining the past knowledge and learning new knowledge to align features. Our extensive experiments with multiple classification and retrieval tasks show that CLIP-Refine succeeds in mitigating the modality gap and improving the zero-shot performance.

    - authors:
        - *adachi
        - *yamaguchi
        - *kumagai
        - *hamagami
      title: Test-time Adaptation for Regression by Subspace Alignment
      published_in: The Thirteenth International Conference on Learning Representations (ICLR 2025), 2025.
      links:
        - Paper: https://proceedings.iclr.cc/paper_files/paper/2025/hash/c19c4def293b6a63db1ff27143dd4f10-Abstract-Conference.html
        - Preprint: https://arxiv.org/abs/2410.03263
        - Poster: /assets/publications/ICLR2025_poster.pdf
        - Code: https://github.com/kzkadc/regression-tta
        - Press release (NTT): https://group.ntt/en/newsrelease/2025/03/18/250318b.html
      abstract: >-
        This paper investigates test-time adaptation (TTA) for regression, where a regression model pre-trained in a source domain is adapted to an unknown target distribution with unlabeled target data. Although regression is one of the fundamental tasks in machine learning, most of the existing TTA methods have classification-specific designs, which assume that models output class-categorical predictions, whereas regression models typically output only single scalar values. To enable TTA for regression, we adopt a feature alignment approach, which aligns the feature distributions between the source and target domains to mitigate the domain gap. However, we found that naive feature alignment employed in existing TTA methods for classification is ineffective or even worse for regression because the features are distributed in a small subspace and many of the raw feature dimensions have little significance to the output. For an effective feature alignment in TTA for regression, we propose Significant-subspace Alignment (SSA). SSA consists of two components: subspace detection and dimension weighting. Subspace detection finds the feature subspace that is representative and significant to the output. Then, the feature alignment is performed in the subspace during TTA. Meanwhile, dimension weighting raises the importance of the dimensions of the feature subspace that have greater significance to the output. We experimentally show that SSA outperforms various baselines on real-world datasets.

    - authors:
        - Taku Sasaki
        - Adam S. Walmsley
        - *adachi
        - Shohei Enomoto
        - *yamaguchi
      title: Key Factors Determining the Required Number of Training Images in Person Re-Identification
      published_in: "IEEE Access, vol. 12, pp. 135135-135147, 2024, doi: 10.1109/ACCESS.2024.3461739."
      links:
        - Paper: https://ieeexplore.ieee.org/document/10681056
      abstract: >-
        Focusing on person re-identification datasets, this paper proposes a new method to estimate the test accuracy curve over the training image number in a precise, interpretable, and efficient manner to receive financial and privacy protection benefits. An existing method, neural scaling law, accurately approximates the curve by fitting a regression function to data points of a training image number and the corresponding accuracy. However, fitting such a function does not explain the reason for the estimated curve. Moreover, obtaining a data point updates model parameters with heavy computation. Therefore, this paper investigates the key factors of a person re-identification dataset that determine the regression parameters. By incorporating the found factors, our method becomes interpretable. Simultaneously, the method significantly reduces computation costs since model updates are no longer needed. We experimentally show that our method is as precise as the uninterpretable neural scaling law incurring nearly millions of model updates.

    - authors:
        - *adachi
        - Shohei Enomoto
        - Taku Sasaki
        - *yamaguchi
      title: Test-time Similarity Modification for Person Re-identification toward Temporal Distribution Shift
      published_in: "2024 International Joint Conference on Neural Networks (IJCNN), Yokohama, Japan, 2024, pp. 1-8, doi: 10.1109/IJCNN60899.2024.10650113."
      links:
        - Paper: https://ieeexplore.ieee.org/document/10650113
        - Preprint: https://arxiv.org/abs/2403.14114
        - Poster: /assets/publications/ijcnn2024_reid-tta.pdf
        - Code: https://github.com/kzkadc/reid-tta
      abstract: >-
        Person re-identification (re-id), which aims to retrieve images of the same person in a given image from a database, is one of the most practical image recognition applications. In the real world, however, the environments that the images are taken from change over time. This causes a distribution shift between training and testing and degrades the performance of re-id. To maintain re-id performance, models should continue adapting to the test environment's temporal changes. Test-time adaptation (TTA), which aims to adapt models to the test environment with only unlabeled test data, is a promising way to handle this problem because TTA can adapt models instantly in the test environment. However, the previous TTA methods are designed for classification and cannot be directly applied to re-id. This is because the set of people's identities in the dataset differs between training and testing in re-id, whereas the set of classes is fixed in the current TTA methods designed for classification. To improve re-id performance in changing test environments, we propose TEst-time similarity Modification for Person re-identification (TEMP), a novel TTA method for re-id. TEMP is the first fully TTA method for re-id, which does not require any modification to pre-training. Inspired by TTA methods that refine the prediction uncertainty in classification, we aim to refine the uncertainty in re-id. However, the uncertainty cannot be computed in the same way as classification in re-id since it is an open-set task, which does not share person labels between training and testing. Hence, we propose re-id entropy, an alternative uncertainty measure for re-id computed based on the similarity between the feature vectors. Experiments show that the re-id entropy can measure the uncertainty on re-id and TEMP improves the performance of re-id in online settings where the distribution changes over time.

    - authors:
        - Shohei Enomoto
        - Naoya Hasegawa
        - *adachi
        - Taku Sasaki
        - *yamaguchi
        - Satoshi Suzuki
        - Takeharu Eda
      title: "Test-time Adaptation Meets Image Enhancement: Improving Accuracy via Uncertainty-aware Logit Switching"
      published_in: "2024 International Joint Conference on Neural Networks (IJCNN), Yokohama, Japan, 2024, pp. 1-8, doi: 10.1109/IJCNN60899.2024.10650964."
      links:
        - Paper: https://ieeexplore.ieee.org/document/10650964
        - Preprint: https://arxiv.org/abs/2403.17423
      abstract: >-
        Deep neural networks have achieved remarkable success in a variety of computer vision applications. However, there is a problem of degrading accuracy when the data distribution shifts between training and testing. As a solution of this problem, Test-time Adaptation (TTA) has been well studied because of its practicality. Although TTA methods increase accuracy under distribution shift by updating the model at test time, using high-uncertainty predictions is known to degrade accuracy. Since the input image is the root of the distribution shift, we incorporate a new perspective on enhancing the input image into TTA methods to reduce the prediction's uncertainty. We hypothesize that enhancing the input image reduces prediction's uncertainty and increase the accuracy of TTA methods. On the basis of our hypothesis, we propose a novel method: Test-time Enhancer and Classifier Adaptation (TECA). In TECA, the classification model is combined with the image enhancement model that transforms input images into recognition-friendly ones, and these models are updated by existing TTA methods. Furthermore, we found that the prediction from the enhanced image does not always have lower uncertainty than the prediction from the original image. Thus, we propose logit switching, which compares the uncertainty measure of these predictions and outputs the lower one. In our experiments, we evaluate TECA with various TTA methods and show that TECA reduces prediction's uncertainty and increases accuracy of TTA methods despite having no hyperparameters and little parameter overhead.

    - authors:
        - *yamaguchi
        - Sekitoshi Kanai
        - *adachi
        - Daiki Chijiwa
      title: Adaptive Random Feature Regularization on Fine-tuning Deep Neural Networks
      published_in: "2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Seattle, WA, USA, 2024, pp. 23481-23490, doi: 10.1109/CVPR52733.2024.02216."
      links:
        - Paper: https://openaccess.thecvf.com/content/CVPR2024/html/Yamaguchi_Adaptive_Random_Feature_Regularization_on_Fine-tuning_Deep_Neural_Networks_CVPR_2024_paper.html
        - Preprint: https://arxiv.org/abs/2403.10097
        - Topics (NTT): https://group.ntt/jp/topics/2024/05/28/cvprntt.html
      abstract: >-
        While fine-tuning is a de facto standard method for training deep neural networks, it still suffers from overfitting when using small target datasets. Previous methods improve fine-tuning performance by maintaining knowledge of the source datasets or introducing regularization terms such as contrastive loss. However, these methods require auxiliary source information (e.g., source labels or datasets) or heavy additional computations. In this paper, we propose a simple method called adaptive random feature regularization (AdaRand). AdaRand helps the feature extractors of training models to adaptively change the distribution of feature vectors for downstream classification tasks without auxiliary source information and with reasonable computation costs. To this end, AdaRand minimizes the gap between feature vectors and random reference vectors that are sampled from class conditional Gaussian distributions. Furthermore, AdaRand dynamically updates the conditional distribution to follow the currently updated feature extractors and balance the distance between classes in feature spaces. Our experiments show that AdaRand outperforms the other fine-tuning regularization, which requires auxiliary source information and heavy computation costs.

    - authors:
        - *adachi
        - *yamaguchi
        - *kumagai
      title: Covariance-aware Feature Alignment with Pre-computed Source Statistics for Test-time Adaptation to Multiple Image Corruptions
      published_in: "2023 IEEE International Conference on Image Processing (ICIP), Kuala Lumpur, Malaysia, 2023, pp. 800-804, doi: 10.1109/ICIP49359.2023.10222901."
      links:
        - Paper: https://ieeexplore.ieee.org/abstract/document/10222901
        - Preprint: https://arxiv.org/abs/2204.13263
        - Poster: https://sigport.org/documents/covariance-aware-feature-alignment-pre-computed-source-statistics-test-time-adaptation
        - Topics (NTT): https://group.ntt/jp/topics/2023/10/08/icip_2023.html
      abstract: >-
        Real-world image recognition systems often face corrupted input images, which cause distribution shifts and degrade the performance of models. These systems often use a single prediction model in a central server and process images sent from various environments, such as cameras distributed in cities or cars. Such single models face images corrupted in heterogeneous ways in test time. Thus, they require to instantly adapt to the multiple corruptions during testing rather than being re-trained at a high cost. Test-time adaptation (TTA), which aims to adapt models without accessing the training dataset, is one of the settings that can address this problem. Existing TTA methods indeed work well on a single corruption. However, the adaptation ability is limited when multiple types of corruption occur, which is more realistic. We hypothesize this is because the distribution shift is more complicated, and the adaptation becomes more difficult in case of multiple corruptions. In fact, we experimentally found that a larger distribution gap remains after TTA. To address the distribution gap during testing, we propose a novel TTA method named Covariance-Aware Feature alignment (CAFe). We empirically show that CAFe outperforms prior TTA methods on image corruptions, including multiple types of corruptions.

    - authors:
        - Yasutoshi Ida
        - Sekitoshi Kanai
        - *adachi
        - *kumagai
        - Yasuhiro Fujiwara
      title: Fast Regularized Discrete Optimal Transport With Group-Sparse Regularizers
      published_in: Proceedings of the AAAI Conference on Artificial Intelligence, vol. 37, no. 7, June 2023, pp. 7980-7, doi:10.1609/aaai.v37i7.25965.
      links:
        - Paper: https://ojs.aaai.org/index.php/AAAI/article/view/25965
        - Preprint: https://arxiv.org/abs/2303.07597
        - Topics (NTT): https://group.ntt/jp/topics/2023/02/07/ntt_aaai2023.html
      abstract: >-
        Regularized discrete optimal transport (OT) is a powerful tool to measure the distance between two discrete distributions that have been constructed from data samples on two different domains. While it has a wide range of applications in machine learning, in some cases the sampled data from only one of the domains will have class labels such as unsupervised domain adaptation. In this kind of problem setting, a group-sparse regularizer is frequently leveraged as a regularization term to handle class labels. In particular, it can preserve the label structure on the data samples by corresponding the data samples with the same class label to one group-sparse regularization term. As a result, we can measure the distance while utilizing label information by solving the regularized optimization problem with gradient-based algorithms. However, the gradient computation is expensive when the number of classes or data samples is large because the number of regularization terms and their respective sizes also turn out to be large. This paper proposes fast discrete OT with group-sparse regularizers. Our method is based on two ideas. The first is to safely skip the computations of the gradients that must be zero. The second is to efficiently extract the gradients that are expected to be nonzero. Our method is guaranteed to return the same value of the objective function as that of the original method. Experiments show that our method is up to 8.6 times faster than the original method without degrading accuracy.

    - authors:
        - *adachi
        - *yamaguchi
      title: Learning Robust Convolutional Neural Networks with Relevant Feature Focusing Via Explanations
      published_in: "2022 IEEE International Conference on Multimedia and Expo (ICME), Taipei, Taiwan, 2022, pp. 1-6, doi: 10.1109/ICME52920.2022.9859838."
      links:
        - Paper: https://ieeexplore.ieee.org/abstract/document/9859838
        - Preprint: https://arxiv.org/abs/2202.04237
      abstract: >-
        Existing image recognition techniques based on convolutional neural networks (CNNs) basically assume that the training and test datasets are sampled from i.i.d distributions. However, this assumption is easily broken in the real world because of the distribution shift that occurs when the co-occurrence relations between objects and backgrounds in input images change. Under this type of distribution shift, CNNs learn to focus on features that are not task-relevant, such as backgrounds from the training data, and degrade their accuracy on the test data. To tackle this problem, we propose relevant feature focusing (ReFF). ReFF detects task-relevant features and regularizes CNNs via explanation outputs (e.g., Grad-CAM). Since ReFF is composed of post-hoc explanation modules, it can be easily applied to off-the-shelf CNNs. Furthermore, ReFF requires no additional inference cost at test time because it is only used for regularization while training. We demonstrate that CNNs trained with ReFF focus on features relevant to the target task and that ReFF improves the test-time accuracy.

    - authors:
        - *adachi_jp
        - *hamagami_jp
      title: 注目領域に基づいたCNNの特徴マップに対する正則化
      published_in: "電子情報通信学会論文誌D, Vol.J102-D, No.3, pp. 185-193, Mar.2019. DOI: 10.14923/transinfj.2018PDP0023."
      links:
        - Paper: https://doi.org/10.14923/transinfj.2018PDP0023
      abstract: >-
        畳み込みニューラルネットワーク（CNN）は画像認識タスクにおいて高性能な特徴抽出を行えることが知られている．しかし，CNNには出力の解釈が困難であるという課題がある．これを緩和するために，近年CNNの予測に寄与した入力画像中の領域（注目領域）を可視化する手法が考案されている．しかし，不十分なデータセットで過学習したモデルの場合，タスクに本質的でない領域に注目している場合がある．このような場合にはモデルの精度が低下するとともに，その解釈も困難になる．そこで本論文では，学習時に注目領域が適切なものとなるように事前知識を与えて正則化を行う手法を提案する．実験により，データセットが少ない場合においても提案手法はモデルの予測の精度を維持しつつ，適切な注目領域が得られることを示す．

- section_name: Conference Workshop / Domestic Conference (Japan)
  papers:
    - authors:
        - *adachi
        - *yamaguchi
        - *kumagai
      title: Test-time Adaptation for Regression by Subspace Alignment
      published_in: (**special mention**) 1st Workshop on Test-time Adaptation (Community Track), CVPR2024 Workshop.
      links:
        - Paper: https://tta-cvpr2024.github.io/_downloads/5c8596c2798bf34ada89ed342bb08d51/matc_1_test_time_adaptation_for_regre.pdf
        - Poster: /assets/publications/cvpr2024_tta-workshop.pdf

    - authors:
        - Taku Sasaki
        - *adachi
        - Shohei Enomoto
        - Yoshihiro Ikeda
        - Adam Walmsley
        - *yamaguchi
      title: Re-training-aware Automatic Model Evaluation for Person Re-identification
      published_in: 画像の認識・理解シンポジウム (MIRU2023), IS2-77, 2023.
      abstract: >-
        This paper proposes the Re-training-aware Automatic model Evaluation for Person Re-identification (RAE-PR), which predicts the performance of a person re-identification model recovered by re-training.
        Conventional Automatic model Evaluation (AutoEval) uses Frechet distance to predict the degraded performance of image classification models before re-training.
        Neural Scaling Laws (NSLs), for arbitrary computer vision tasks, regress the performance curve of the re-training image volume; however, label annotation to evaluate the performance can be costly.
        To predict recovered performance without labels, RAE-PR uses domain embedding and linear mapping modules.
        The former is a hand-crafted module that converts unlabeled images from a domain into factors in replace for classification-specific Frechet distance, namely the number of cameras in the dataset, image luminance mean and deviation, and the person-wise image volume.
        The latter is a trainable module that solves a meta-regression problem from the factors to the regression parameters, which is trained with several datasets from different domains and the corresponding performance.
        In the experiments, we used some variants of MSMT17 datasets to train the latter module and confirmed RAE-PR draws the Market-1501 and PersonX performance curves at comparable root mean squared errors to NSLs.

    - authors:
        - 井田 安俊
        - 金井 関利
        - *adachi_jp
        - 熊谷 充敏
        - 藤原 靖宏
      title: グループ正則化付き離散最適輸送の高速化
      published_in: 電子情報通信学会 情報論的学習理論と機械学習研究会(IBISML)研究会, 2023年6月.
      links:
        - Paper: https://ken.ieice.org/ken/paper/20230629fCv0/eng/
      abstract: >-
        When we use discrete optimal transport (OT) for unsupervised domain adaptation, a group-sparse regularizer is frequently leveraged to preserve label information on data samples. However, the gradient computation is expensive when the number of classes or data samples is large. We propose fast discrete OT with group-sparse regularizers. The main idea is to skip the computations of the gradients that must be zeros. Our method is guaranteed to return the same value of the objective function as that of the original method. Experiments show that our method is up to 8.6 times faster than the original method without degrading accuracy.

    - authors:
        - *adachi_jp
        - 山口 真弥
      title: 深層学習モデルの判断根拠を利用した偏りを持つデータセットに対する精度向上
      published_in: (**2020年度PRMU研究奨励賞**) 電子情報通信学会 パターン認識・メディア理解(PRMU)研究会, 2021年3月.
      links:
        - Paper: https://ken.ieice.org/ken/paper/20210305gCcs/eng/
      abstract: >-
        Although it is desirable that training datasets for deep learning have diverse features, datasets that have biased features irrelevant to target tasks are likely to be created actually. Deep learning models trained on such biased datasets degrade its accuracy toward input distribution shift. To tackle this problem, we propose Independent Feature Focusing (IFF), the method to detect features on which models should focus and regularize its attribution to improve accuracy.

    - authors:
        - *adachi_jp
        - 中田 雅也
        - *hamagami_jp
      title: CNNの注目領域を利用した事前知識の組み込みによる正則化
      published_in: 計測自動制御学会 第45回知能システムシンポジウム講演論文集, B2-1, 2018.
      abstract: >-
        畳み込みニューラルネットワーク（CNN）は判断の過程がブラックボックスであり，その根拠を解釈することは難しい。この問題に対処するために，CNNモデルの予測に寄与した入力画像中の領域を可視化する手法が考案されている。しかし，これらの可視化手法はモデル自体を改善するものではない。具体的には，十分でないデータセットで学習したモデルの判断根拠を可視化すると，不適切な領域に注目している場合が多く，解釈が難しい。そこで本研究では，不適切な注目領域に対する罰則を設けて学習を行うことで，見るべき領域に関する事前知識を学習時に入れ込む手法を提案した。実験により，データセットが少ない場合においても提案手法で学習したモデルは予測の精度を維持しつつ適切な領域に注目することを示した。

    - authors:
        - *adachi_jp
        - *hamagami_jp
      title: CNNにおける事前知識を利用した学習方法の検討
      published_in: 第28回インテリジェント・システム・シンポジウム(FAN2018), ST-18-095, 2018.

    - authors:
        - 佐々木 勇人
        - *adachi_jp
        - *hamagami_jp
        - 山本 みずき
        - 竹島 徹平
        - 湯村 寧
      title: 生殖医療支援を目的とした顕微鏡動画像における精子検出
      published_in: 第16回情報科学技術フォーラム(FIT2017), CH-005, 2017.
      links:
        - Paper: https://www.ieice.org/publications/conference-FIT-DVDs/FIT2017/data/pdf/CH-005.pdf
      abstract: >-
        顕微授精において，胚培養士の肉眼による精子選別作業は受精率に大きな影響を及ぼす。しかしながら精子選別作業は経験に基づく高度な知識と技術を要すだけでなく，限られた視野・時間のもとで有望な精子を見つけ出さなければならない。本研究は精子選別を支援を目的として，顕微鏡動画像の精子検出を実現する。顕微鏡動画像中には精子以外にも白血球や精母細胞などが多数存在する。すなわち精子以外を無視する必要がある。本研究では局所特徴抽出と機械学習を組み合わせることにより，限られた時間の中で精子とそれ以外を識別する手法を提案し，実際の顕微鏡動画像に対して精子検出の性能を評価する。

    - authors:
        - *adachi_jp
        - 佐々木 勇人
        - 中田 雅也
        - 濱津 文哉
        - *hamagami_jp
      title: 転移学習によるDeep Q-Networkの学習高速化に向けた検討
      published_in: 情報処理学会 第79回全国大会講演論文集, 5M-09, 2017.
      abstract: >-
        Q-Learningに深層学習を取り入れた手法であるDeep Q-Network（DQN）には，従来のQ-Learningでは扱いきれない画像のような高次元の観測を直接扱うことができるという利点がある。しかし，課題として学習には膨大な回数のエピソードを繰り返す必要がある。この課題に対処するために，別のタスクで学習済みの畳み込みニューラルネットワーク（CNN）を利用した転移学習が行われている。転移学習によりエージェントはタスクに有用な特徴抽出を行える状態から学習を開始できると考えられる。本稿では転移を行うCNNの層数を変化させ，学習回数や得られる報酬にどのような影響が現れるかを実験により調査する。

- section_name: Other Publication / Preprint
  papers:
    - authors:
        - 千々和 大輝
        - 熊谷 充敏
        - *adachi_jp
        - 井田 安俊
      title: AIコンステレーション®を支える先端AIアルゴリズム研究
      published_in: "NTT技術ジャーナル, 2025年9月号, pp. 17-21, doi: 10.60249/25095004."
      links:
        - Article: https://journal.ntt.co.jp/article/36096
      abstract: >-
        AIコンステレーション®の基盤技術としての活用を志向する先端AI（人工知能）アルゴリズムの研究事例を紹介します。具体的には、学習結果の再利用を可能にするNTT発「学習転移」技術、偏ったデータの環境変化に低ラベリングコストで適応するための転移学習技術、数値予測モデル向けのテスト時適応技術、多種多様な大規模高次元データ分析のためのスパースモデリング技術について解説します。

    - authors:
        - *adachi
        - *yamaguchi
        - *hamagami
      title: "Uniformity First: Uniformity-aware Test-time Adaptation of Vision-language Models against Image Corruption"
      published_in: "arXiv preprint arXiv:2505.12912 (2025)."
      links:
        - Preprint: https://arxiv.org/abs/2505.12912
        - Code: https://github.com/kzkadc/uninfo
      abstract: >-
        Pre-trained vision-language models such as contrastive language-image pre-training (CLIP) have demonstrated a remarkable generalizability, which has enabled a wide range of applications represented by zero-shot classification. However, vision-language models still suffer when they face datasets with large gaps from training ones, i.e., distribution shifts. We found that CLIP is especially vulnerable to sensor degradation, a type of realistic distribution shift caused by sensor conditions such as weather, light, or noise. Collecting a new dataset from a test distribution for fine-tuning highly costs since sensor degradation occurs unexpectedly and has a range of variety. Thus, we investigate test-time adaptation (TTA) of zero-shot classification, which enables on-the-fly adaptation to the test distribution with unlabeled test data. Existing TTA methods for CLIP mainly focus on modifying image and text embeddings or predictions to address distribution shifts. Although these methods can adapt to domain shifts, such as fine-grained labels spaces or different renditions in input images, they fail to adapt to distribution shifts caused by sensor degradation. We found that this is because image embeddings are "corrupted" in terms of uniformity, a measure related to the amount of information. To make models robust to sensor degradation, we propose a novel method called uniformity-aware information-balanced TTA (UnInfo). To address the corruption of image embeddings, we introduce uniformity-aware confidence maximization, information-aware loss balancing, and knowledge distillation from the exponential moving average (EMA) teacher. Through experiments, we demonstrate that our UnInfo improves accuracy under sensor degradation by retaining information in terms of uniformity.

    - authors:
        - *adachi_jp
        - 内田 美尋
      title: ICIP2023参加報告
      published_in: 映像情報メディア学会誌, 2024年3月号 (Vol.78 No.2).

- section_name: Patent
  papers:
    - authors:
        - *adachi
        - *yamaguchi
        - Shohei Enomoto
        - Taku Sasaki
        - Yoshihiro Ikeda
      title: MODEL ADAPTATION DEVICE, MODEL ADAPTATION METHOD, AND MODEL ADAPTATION PROGRAM (モデル適応装置、モデル適応方法、および、モデル適応プログラム)
      published_in: PCT/JP2023/029364.
      links:
        - WO: https://patentscope2.wipo.int/search/en/detail.jsf?docId=WO2025032828

    - authors:
        - Taku Sasaki
        - *adachi
        - *yamaguchi
        - Yoshihiro Ikeda
        - Shohei Enomoto
      title: PREDICTION DEVICE, PREDICTION METHOD, AND PREDICTION PROGRAM (予測装置、予測方法及び予測プログラム)
      published_in: PCT/JP2023/024461.
      links:
        - WO: https://patentscope2.wipo.int/search/en/detail.jsf?docId=WO2025004356

    - authors:
        - *adachi
        - *yamaguchi
      title: TRAINING DEVICE, TRAINING METHOD, AND TRAINING PROGRAM (学習装置、学習方法、および、学習プログラム)
      published_in: WO2023/181222, 特許第7670230号.
      links:
        - WO: https://patentscope2.wipo.int/search/en/detail.jsf?docId=WO2023181222
        - JP: https://www.j-platpat.inpit.go.jp/c1801/PU/JP-7670230/15/ja

    - authors:
        - *adachi
        - *yamaguchi
      title: LEARNING DEVICE, LEARNING METHOD, AND LEARNING PROGRAM (学習装置、学習方法及び学習プログラム)
      published_in: WO2022/176116, 特許第7613551号.
      links:
        - WO: https://patentscope.wipo.int/search/en/detail.jsf?docId=WO2022176116
        - JP: https://www.j-platpat.inpit.go.jp/c1801/PU/JP-7613551/15/ja

    - authors:
        - *adachi
        - Tetsuya Shioda
        - Machiko Toyoda
      title: IMPORTANCE DEGREE CALCULATION DEVICE, IMPORTANCE DEGREE CALCULATION METHOD, AND IMPORTANCE DEGREE CALCULATION PROGRAM (重要度計算装置、重要度計算方法及び重要度計算プログラム)
      published_in: WO2022/038722, 特許第7491382号.
      links:
        - WO: https://patentscope.wipo.int/search/en/detail.jsf?docId=WO2022038722
        - JP: https://www.j-platpat.inpit.go.jp/c1801/PU/JP-7491382/15/ja

    - authors:
        - Tetsuya Shioda
        - Machiko Toyoda
        - *adachi
        - Masakuni Ishii
      title: VISUALIZATION DEVICE, VISUALIZATION METHOD, AND VISUALIZATION PROGRAM (可視化装置、可視化方法および可視化プログラム)
      published_in: WO2022/038713, 特許第7464132号.
      links:
        - WO: https://patentscope.wipo.int/search/en/detail.jsf?docId=WO2022038713
        - JP: https://www.j-platpat.inpit.go.jp/c1801/PU/JP-7464132/15/ja
